# Qualitative Analysis for Client/Stakeholder Communication
# Category: Meta-Work

This report is an AI-generated synthesis of manually coded survey responses from software developers about AI usage in Client/Stakeholder Communication (Meta-Work). I preserved the research team’s thematic structure and codes, integrated representative participant quotes, and added cross-cutting analysis and practical design implications. The analysis focuses only on the supplied coded data.

---

## 1) Core Themes

### A. Where AI is Wanted

#### Theme: Rote Task Automation in Communication  ( Automated stakeholder updates & progress reports, Note-taking & recap, Scheduling & follow-ups, Boilerplate drafting)

Participants consistently imagine AI taking over repetitive, low-value communication chores so humans can focus on higher-value work. The researchers’ code description states that “AI is expected to take over repetitive, low-value communication chores: scheduling meetings, generating reports, taking notes, sending routine updates, drafting boilerplate docs/emails.” Respondents describe concrete, time-consuming tasks they would delegate: calendar coordination, progress-report drafting from work tracking systems, note-taking and recaps of missed meetings, and routine email responses. For example, one participant framed a scheduling ask concretely: “Meeting scheduling. Here is a list of names put a meeting on the calendar with a room and Teams link.” (Participant 50). Others want draft reports or recaps delivered for quick proofreading rather than fully autonomous action: “I would like the AI to 1) automatically generate progress reports using my ADOs and send me a draft for proof reading…” (Participant 72). Boundaries are often implicit — people want AI to reduce cognitive burden and handle mundane steps, but several comments imply the drafts should be reviewable before sending.

The motivation is efficiency and reclaiming time: “Communication takes a lot of time. I hope AI can take it.” (Participant 327). Specific outcomes participants expect are reduced overhead for routine updates, faster onboarding to meeting content via recaps, and fewer manual scheduling tasks. Participants also highlight use-cases where AI could be continuous support (e.g., automated follow-ups and recap features) but imply they will retain final control over tone and approval. Representative quotes below show the mix of delegation and desire for review.

Sub-themes identified:
- **Automated stakeholder updates & progress reports**: AI generates routine updates and drafts based on tracked work.
- **Note-taking & recap**: AI transcribes and summarizes meetings to accelerate catching up.
- **Scheduling & follow-ups**: AI handles meeting setup, reminders, and routine follow-ups.
- **Boilerplate drafting**: AI creates templated emails/docs that developers can edit.

**Representative quotes**:
- *“Meeting scheduling. Here is a list of names put a meeting on the calendar with a room and Teams link.”* (Participant 50)  
- *“I would like the AI to 1) automatically generate progress reports using my ADOs and send me a draft for proof reading…”* (Participant 72)  
- *“Just doing any mundane rote work like taking notes.”* (Participant 186)  
- *“The killer Copilot feature for me is Recap, allowing me to quickly catch up on meetings I missed.”* (Participant 198)  
- *“It should be able to respond to repetitive emails, take notes, take easy follow-ups (send emails, set up meetings, etc).”* (Participant 357)

---

#### Theme: Improving communication clarity and accessibility through tailored support  (Tailoring to stakeholder/customer needs, Simplifying technical details,Multilingual/cultural phrasing)

This theme centers on AI as a clarity and accessibility engine: tailoring messages for different stakeholders, translating or adapting tone for cultural contexts, and simplifying technical explanations. The researcher description captures this: “AI is envisioned as a clarity enhancer: tailoring communications to different audiences, simplifying technical jargon, and ensuring culturally/linguistically appropriate messaging.” Participants want help reframing technical content into clear, audience-appropriate language — for example, “Rephrase words to stakeholders or client… help to explain the tech details… in an easy understandable way.” (Participant 127). Non-English contexts also appear as a distinct need: “I want AI suggestions for communication with external partners, particularly when I’m writing in Japanese rather than English… focused comments on correct use of polite forms.” (Participant 175). The desired outcome is improved stakeholder comprehension and reduced risk of miscommunication, especially when language or cultural norms matter.

Participants envision AI as a co-writer that adapts messages but still allows human oversight and customization. Several responses imply the AI should propose phrasing and structure rather than replace the author’s voice: “I would like AI to help with tailoring stakeholder communications to different stakeholders.” (Participant 39). The boundary here is that the tool should respect nuance — technical accuracy must be preserved while simplifying, and cultural adjustments should be sensitive and optional.

Sub-themes identified:
- **Tailoring to stakeholder/customer needs**: Adapting tone and content per audience.
- **Simplifying technical details**: Turning technical language into accessible explanations.
- **Multilingual/cultural phrasing**: Helping with language, politeness, and cultural norms.

**Representative quotes**:
- *“I would like AI to help with tailoring stakeholder communications to different stakeholders.”* (Participant 39)  
- *“Rephrase words to stakeholders or client… help to explain the tech details… in an easy understandable way.”* (Participant 127)  
- *“I want AI suggestions for communication with external partners, particularly when I’m writing in Japanese rather than English… focused comments on correct use of polite forms.”* (Participant 175)  
- *“Help with communication with customers.”* (Participant 200)

---

#### Theme: Logistic and Coordination Support  (Scheduling & meeting prep, Tracking alignment & next steps, Reminders & project coordination)

Under this theme participants see AI as an active coordination agent that goes beyond rote tasks to orchestrate workflows and keep projects aligned. The research description frames AI as “handling scheduling, surfacing alignment across goals and teams, and supporting project-level coordination.” Respondents express needs such as meeting preparation, surfacing where actions are required across teams, and proactive reminders about priorities: “Project management and communication. It can tell where the project goes and where to go and what I should do today (email, ping someone).” (Participant 232). Another participant asks the AI to be a “personal agent” that “Keep track of my work and thoughts and be able to attend meetings or answer some questions on my behalf.” (Participant 204), indicating an expectation for contextual persistence and proactive behavior.

The context driving this desire is the fragmentation of modern work: multiple teams, shifting priorities, and the overhead of keeping stakeholders aligned. Participants want AI to reduce cognitive load by surfacing alignment issues and next steps, not just execute prompts. However, this orchestration desire coexists with caution about autonomy; participants typically imply a graded level of agency (e.g., suggestions, reminders, or limited representation in meetings) rather than full independence. Representative quotes illustrate both the orchestration expectation and the practical tasks (scheduling/meeting prep) that support it.

Sub-themes identified:
- **Scheduling & meeting prep**: Coordinating logistics and preparing materials.
- **Tracking alignment & next steps**: Surfacing cross-team alignment and recommended actions.
- **Reminders & project coordination**: Proactive nudges and work prioritization.

**Representative quotes**:
- *“Help with meeting and communication, help me find new tools and learnings…”* (Participant 142)  
- *“I want AI to support meta work by streamlining documentation, meeting prep, and cross-functional alignment…”* (Participant 172)  
- *“Be my personal agent. Keep track of my work and thoughts and be able to attend meetings or answer some questions on my behalf.”* (Participant 204)  
- *“Project management and communication. It can tell where the project goes and where to go and what I should do today (email, ping someone).”* (Participant 232)  
- *“Helping track alignment across goals and teams. These meta work tasks often consume time but are critical for clarity and coordination.”* (Participant 403)

---

#### Theme: Contextual Information Collation and Sensemaking  (Summarizing discussions/docs, Synthesizing across workflows, Supporting onboarding/knowledge transfer)

This theme frames AI as a unifier of fragmented context: synthesizing meeting notes, documents, and project data to produce coherent, reusable knowledge. The researchers’ description says AI should “bring together information across sources (meetings, documents, project data) to reduce fragmentation” and to support onboarding and knowledge transfer. Participants explicitly ask for summarization of meetings and technical documents and help drafting documentation: “Summarizing technical documents, writing communications.” (Participant 164). They want AI that preserves institutional memory and assists onboarding: “Helping me brain dump the knowledge I’ve gained over the years to help customers and onboard new people.” (Participant 401).

The motivation is both efficiency (quick access to critical info) and risk mitigation (reducing lost knowledge). Some responses also suggest AI might reduce human biases in documentation and capture customer interactions reliably: “AI assistants in documentation/note taking in customer interactions might reduce human biases.” (Participant 369). Boundaries include ensuring summaries are accurate and comprehensive enough for handover purposes; participants imply continued human oversight for final documentation and onboarding artifacts.

Sub-themes identified:
- **Summarizing discussions/docs**: Condensing meetings and documents into usable summaries.
- **Synthesizing across workflows**: Combining information from multiple systems and artifacts.
- **Supporting onboarding/knowledge transfer**: Turning tacit knowledge into accessible resources.

**Representative quotes**:
- *“Reviewing, summarizing.”* (Participant 163)  
- *“Summarizing technical documents, writing communications.”* (Participant 164)  
- *“Summarizing meetings and communication, helping draft documentation.”* (Participant 217)  
- *“…help in troubleshooting documentation, thus helping in onboarding as well.”* (Participant 271)  
- *“Helping me brain dump the knowledge I’ve gained over the years to help customers and onboard new people.”* (Participant 401)

---

### B. Where AI is Not Wanted

#### Theme: Need for human oversight

Across many responses, participants insist on human review, editing, or approval of AI-generated communications to guard against hallucinations and incorrect content. The researchers’ description captures this: “Participants insist on reviewing, editing, or approving AI-generated communication before sending to avoid hallucinations or errors.” Several respondents state this as a strict boundary: “AI should definitely not be the primary factor in documentation, communication, or mentoring/onboarding. Its tendency to hallucinate is too great to risk in these areas without significant human oversight.” (Participant 17). Others are explicit that AI should not send emails autonomously: “I don't want it to send emails on my behalf without me proof reading first.” (Participant 72); “Shouldn't send an email without my permission/viewing it first.” (Participant 102).

The concern is twofold: factual errors and reputational risk. Participants want AI to be a drafting or suggestion tool, not an autonomous agent in client-facing or internal mentoring contexts. They also suggest tiers of oversight depending on task sensitivity: “There should still be varying levels of human oversight depending on the task.” (Participant 204). The boundary is clear — oversight is non-negotiable for many, and autonomy must be constrained.

**Representative quotes**:
- *“AI should definitely not be the primary factor in documentation, communication, or mentoring/onboarding. Its tendency to hallucinate is too great to risk in these areas without significant human oversight.”* (Participant 17)  
- *“I don't want it to send emails on my behalf without me proof reading first.”* (Participant 72)  
- *“Shouldn't send an email without my permission/viewing it first.”* (Participant 102)  
- *“I believe AI can handle all of them to some extent, but I wouldn't want AI to be entirely autonomous. There should still be varying levels of human oversight depending on the task.”* (Participant 204)

---

#### Theme: Authenticity and personal touch (empathy, trust, dynamics)

Participants emphasize that certain stakeholder interactions require a genuine human voice, empathy, and nuanced understanding — elements they do not want AI to replace. The description states: “Emphasis on genuine human voice, empathy, and authentic relationship-building, especially for managers and team leaders.” Several responses make a principled stand: “I don't want AI directly communicating on my behalf.” (Participant 123), and “I don't want AI to write emails… we should all (managers in particular) express our authentic selves to our colleagues.” (Participant 175). Managers worry about losing trust and relational subtleties: “I don’t want AI to handle sensitive stakeholder communications… these require empathy, trust-building, and nuanced understanding of team dynamics.” (Participant 172).

The feared outcomes are depersonalized relationships, loss of managerial authenticity, and erosion of trust. Participants allow AI to help with logistics or summarization but resist delegation of relational work. They prefer AI to augment their voice (e.g., suggest phrasing) rather than substitute for it. Representative quotes underscore the boundary between assistance and replacement.

**Representative quotes**:
- *“I don't want AI directly communicating on my behalf.”* (Participant 123)  
- *“I do not use AI to write emails or docs. If I expect a human to read it, I'm going to take the time to write it myself.”* (Participant 167)  
- *“I don’t want AI to handle sensitive stakeholder communications… these require empathy, trust-building, and nuanced understanding of team dynamics.”* (Participant 172)  
- *“Client communication needs to have a personal touch. Summarizing meetings is one thing, but replacing real touch points is too much.”* (Participant 217)

---

#### Theme: Privacy and risk concerns

Respondents express worries about confidentiality, sensitive data handling, and risk amplification through AI errors. The manual description notes concerns about “mishandling sensitive information, confidentiality breaches, and risks tied to hallucinations.” Comments such as “E2E customer communications, want to oversee communications closely.” (Participant 160) and “Client/Stakeholder Communication as its risky in terms for privacy.” (Participant 180) indicate that participants see direct client interactions as high-risk domains. Some explicitly do not want AI to handle stakeholder communication at all: “I don't think AI should be handling communication with stakeholders.” (Participant 188).

These concerns translate to boundaries around data access and processing: participants expect strict controls or opt-outs where confidential information is involved. The presence of confidential or regulated data is a clear disqualifier for full AI automation in many respondents’ views.

**Representative quotes**:
- *“E2E customer communications, want to oversee communications closely.”* (Participant 160)  
- *“Client/Stakeholder Communication as its risky in terms for privacy.”* (Participant 180)  
- *“I don't think AI should be handling communication with stakeholders.”* (Participant 188)  
- *“to handle confidentional data.”* (Participant 329)

---

#### Theme: Limited usefulness for niche communication

A minority of responses emphasize that AI has limited value for some client or stakeholder interactions because those interactions are rare, highly specific, or inherently human. The descriptive note reads: “Some saw little value since their communication tasks are rare, context-specific, or inherently human.” For example, one participant noted “Customer communication for me is rare and precise enough that standard chatGPT AI is not that useful.” (Participant 189). Others believe human handling remains preferable: “Communication is very complex and critical with multiple stakeholders. That can be handled by humans.” (Participant 237).

Here the context is task frequency and complexity: if interactions are infrequent and nuanced, the overhead of configuring AI or the risk of errors outweighs benefits. Several responses suggest AI could still help by suggesting options rather than taking over the task: “communication with the client and stakeholders. AI should suggest what can be done.” (Participant 332). The boundary is pragmatic: use AI where it yields clear efficiency gains; refrain where it adds friction or risk.

**Representative quotes**:
- *“Communicating with coworkers.”* (Participant 23)  
- *“Customer communication for me is rare and precise enough that standard chatGPT AI is not that useful.”* (Participant 189)  
- *“Communication is very complex and critical with multiple stakeholders. That can be handled by humans.”* (Participant 237)  
- *“communication with the client and stakeholders. AI should suggest what can be done.”* (Participant 332)

---

## 2) Cross-Cutting Patterns

- Complementary desires and concerns: Developers want AI to relieve routine burdens (scheduling, recaps, drafting) while simultaneously guarding authenticity, privacy, and correctness. The “Want AI” themes emphasize efficiency, clarity, and orchestration, whereas the “Don’t want AI” themes demand oversight and preservation of human judgment — producing a clear complementarity where AI is seen as an assistant, not a replacement.

- Conditional acceptance: Acceptance of AI is highly conditional. Common conditions include human review before sending, limited or tiered autonomy depending on task sensitivity, and strong data governance for client-facing content. Several participants explicitly frame oversight as variable by task: some automations may be allowed (recaps, scheduling), while sensitive communications require human authorship or at least final sign-off.

- Task-specific nuances: Client Stakeholder Communication is distinct from code or dev tasks because it blends factual accuracy with relational and cultural nuance. Unlike code-generation, where correctness can be tested, stakeholder communication carries reputational, legal, and emotional stakes. This makes features like tone adaptation, cultural phrasing, and privacy controls especially salient.

- Trust and control dynamics: Trust is not binary; it is mediated by visibility, control, and predictability. Participants are more likely to trust AI when it is transparent (drafts visible), controllable (edit before send), and reliable (accurate summaries). There is a strong preference for human-in-the-loop workflows that preserve authorship and enable auditability.

---

## 3) Outliers and Edge Cases

- Minority perspectives that contradict dominant themes: A few participants suggest higher AI agency (e.g., attending meetings or answering on one’s behalf: Participant 204’s “Be my personal agent… be able to attend meetings or answer some questions on my behalf”). This contrasts with the prevalent insistence on human oversight and raises questions about delegated representation in controlled contexts.

- Unique insights that don't fit neatly: The idea that AI might reduce human biases in customer documentation (Participant 369) is a distinct benefit not widely emphasized elsewhere. This frames AI as not only an efficiency tool but also a potential quality- and fairness-enhancer for recorded interactions.

- Ambivalent responses: Several participants simultaneously ask for extensive AI help (summaries, drafts) and insist on final human approval. These ambivalent responses show practical willingness to use AI for production help while maintaining moral and legal responsibility.

- Contradictions within individuals: Some participants assert a principled stance against AI-written communications (e.g., Participant 167 “I do not use AI to write emails or docs”) yet ask for AI assistance for other communication aspects (summaries or drafts). This indicates role- and context-dependent boundaries rather than absolute rejection.

---

## 4) Implications for AI Tool Design

Overall synthesis: Developers want AI that accelerates and clarifies stakeholder communication while preserving human judgment, authenticity, and data privacy. Tools should be designed as configurable assistants that automate low-value work, synthesize context, and adapt tone, but always provide transparent drafts, audit trails, and granular privacy/permission controls.

#### Key "Must Haves" (features designers should prioritize)

- **Rote Task Automation (scheduling, recaps, drafts)**
  - Capability: Automated meeting scheduling, calendar coordination, note-taking, meeting recaps, and draft progress reports generated from source systems (e.g., ADO).
  - Rationale: Participants explicitly requested automation of repetitive chores to reduce cognitive load (“Meeting scheduling… put a meeting on the calendar…” — Participant 50; “automatically generate progress reports… send me a draft for proof reading…” — Participant 72).
  - Implementation note: Provide editable drafts and easy approval workflows.

- **Audience-tailored phrasing and translation**
  - Capability: Suggest rephrasing to match stakeholder knowledge level, translate/adapt tone for other languages and cultures, and provide politeness/tone recommendations.
  - Rationale: Developers asked for help simplifying technical details and for language-specific suggestions (“Rephrase… help to explain the tech details…” — Participant 127; Japanese politeness help — Participant 175).
  - Implementation note: Allow users to select audience type (e.g., executive, technical, external partner) and language formality level.

- **Contextual collation and summarization**
  - Capability: Aggregate meeting notes, documents, and project data into coherent summaries and action items; support knowledge capture for onboarding.
  - Rationale: Participants want unified context to reduce fragmentation and aid onboarding (“Summarizing meetings… helping draft documentation.” — Participant 217; “brain dump the knowledge… onboard new people.” — Participant 401).
  - Implementation note: Link summaries to source materials and provide traceable citations.

- **Coordination assistant with prioritized nudges**
  - Capability: Surface alignment gaps, flag next steps, and provide daily/weekly prioritized actions across projects.
  - Rationale: Participants value orchestration that helps manage cross-functional work (“tell where the project goes…what I should do today” — Participant 232).
  - Implementation note: Make recommendations adjustable and explainable.

- **Human-in-the-loop controls and auditability**
  - Capability: Mandatory review-and-approve flows for outbound communications, editable drafts with visible provenance, and explicit indicators of AI-suggested content.
  - Rationale: Strong insistence on oversight to prevent hallucinations and preserve accountability (“Shouldn't send an email without my permission/viewing it first.” — Participant 102).
  - Implementation note: Provide configurable autonomy levels per communication category.

#### Key "Must Not Haves" (design guardrails)

- **Autonomous outbound communication for sensitive stakeholder interactions**
  - Risk: Reputation, legal, and privacy harm from unsupervised messages.
  - Rationale: Participants explicitly forbade unsupervised sending (“I don't want it to send emails on my behalf without me proof reading first.” — Participant 72).
  - Design guardrail: Disallow automated sending in high-sensitivity channels by default; require explicit opt-in with strict audit logs.

- **Opaque decision-making / lack of provenance**
  - Risk: Loss of trust and inability to verify AI claims.
  - Rationale: Need for human oversight implies demand for traceable sources (“automatically generate progress reports using my ADOs and send me a draft for proof reading…” — Participant 72).
  - Design guardrail: Always surface source citations and transformation steps for summaries and drafted content.

- **Default replacement of personal/managerial voice**
  - Risk: Erosion of authenticity and team trust.
  - Rationale: Managers and leads stressed personal touch as non-negotiable (“we should all (managers in particular) express our authentic selves” — Participant 175).
  - Design guardrail: Default to suggestion mode, not send-on-behalf; provide templates that preserve user edits and signature.

- **Uncontrolled access to confidential stakeholder data**
  - Risk: Privacy breaches and compliance violations.
  - Rationale: Participants flagged privacy concerns for client communications (“Client/Stakeholder Communication as its risky in terms for privacy.” — Participant 180).
  - Design guardrail: Implement role-based access, data residency controls, and opt-out toggles for processing sensitive threads.

- **One-size-fits-all tone/translations without cultural nuance**
  - Risk: Miscommunication or offense in multilingual/cultural contexts.
  - Rationale: Participants requested culturally-aware phrasing (“focused comments on correct use of polite forms.” — Participant 175).
  - Design guardrail: Provide locale and register settings; require human confirmation for culturally sensitive rewrites.

---

## Executive Summary

- Developers want AI to automate repetitive communication tasks (scheduling, recaps, boilerplate drafting) so they can focus on higher-value work.
- They also seek AI assistance for clarity and accessibility: tailoring messages to audiences, simplifying technical content, and adapting language/formality.
- Critical design imperatives are human-in-the-loop controls, provenance/transparency for generated content, and strict privacy safeguards for client-facing communications.
- Tools should prioritize contextual summarization and coordination features (action-item surfacing, prioritized nudges) that reduce fragmentation across projects.
- There is a clear tension between efficiency gains and preserving authenticity/trust; many developers accept AI drafts but insist on personal oversight and final control.
- Recommendation: Build configurable assistants that default to suggestion-and-review modes, surface sources and rationale, and enforce strict data/access controls for stakeholder communication.